{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML: Player Churn Prediction Model\n",
        "\n",
        "**Notebook:** `01_player_churn_prediction`  \n",
        "**Type:** Machine Learning  \n",
        "**Purpose:** Predict player churn risk using historical behavior patterns\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates building a player churn prediction model using Fabric's ML capabilities. The model identifies players at risk of becoming inactive, enabling proactive retention efforts.\n",
        "\n",
        "### Business Value\n",
        "- Early identification of at-risk players\n",
        "- Targeted retention campaigns\n",
        "- Improved player lifetime value\n",
        "- Optimized marketing spend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "GOLD_LAKEHOUSE = \"lh_gold\"\n",
        "MODEL_NAME = \"player_churn_model\"\n",
        "CHURN_DAYS_THRESHOLD = 30  # Player inactive for 30+ days = churned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import (\n",
        "    VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder\n",
        ")\n",
        "from pyspark.ml.classification import (\n",
        "    RandomForestClassifier, LogisticRegression, GBTClassifier\n",
        ")\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "import mlflow\n",
        "import mlflow.spark\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Enable MLflow autologging\n",
        "mlflow.spark.autolog()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_player_features(snapshot_date: str = None):\n",
        "    \"\"\"\n",
        "    Create feature dataset for churn prediction.\n",
        "    \n",
        "    Features include:\n",
        "    - Recency: Days since last visit\n",
        "    - Frequency: Visit count in last 90 days\n",
        "    - Monetary: Total coin-in in last 90 days\n",
        "    - Behavioral: Win rate, avg session length, preferred games\n",
        "    \"\"\"\n",
        "    if snapshot_date is None:\n",
        "        snapshot_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    \n",
        "    # Read slot telemetry\n",
        "    df_slots = spark.table(\"silver_slot_telemetry\") \\\n",
        "        .filter(col(\"player_id\") != \"ANONYMOUS\") \\\n",
        "        .filter(col(\"event_type\") == \"SPIN\")\n",
        "    \n",
        "    # Read player dimension\n",
        "    df_player = spark.table(\"dim_player\") \\\n",
        "        .filter(col(\"is_current\") == True)\n",
        "    \n",
        "    # Calculate player-level metrics\n",
        "    df_features = df_slots.groupBy(\"player_id\").agg(\n",
        "        # Recency\n",
        "        datediff(lit(snapshot_date), max(\"event_timestamp\")).alias(\"days_since_last_visit\"),\n",
        "        \n",
        "        # Frequency (last 90 days)\n",
        "        count(when(col(\"event_timestamp\") >= date_sub(lit(snapshot_date), 90), 1)).alias(\"visits_90d\"),\n",
        "        countDistinct(when(col(\"event_timestamp\") >= date_sub(lit(snapshot_date), 90), \n",
        "                          to_date(\"event_timestamp\"))).alias(\"active_days_90d\"),\n",
        "        \n",
        "        # Monetary\n",
        "        sum(when(col(\"event_timestamp\") >= date_sub(lit(snapshot_date), 90), \n",
        "                col(\"bet_amount\")).otherwise(0)).alias(\"coin_in_90d\"),\n",
        "        sum(when(col(\"event_timestamp\") >= date_sub(lit(snapshot_date), 90), \n",
        "                col(\"win_amount\")).otherwise(0)).alias(\"coin_out_90d\"),\n",
        "        \n",
        "        # Behavioral\n",
        "        avg(\"bet_amount\").alias(\"avg_bet_amount\"),\n",
        "        stddev(\"bet_amount\").alias(\"bet_volatility\"),\n",
        "        count(when(col(\"win_amount\") > 0, 1)).alias(\"win_count\"),\n",
        "        count(\"*\").alias(\"total_spins\"),\n",
        "        countDistinct(\"machine_id\").alias(\"unique_machines\"),\n",
        "        countDistinct(\"session_id\").alias(\"total_sessions\"),\n",
        "        \n",
        "        # Time patterns\n",
        "        min(\"event_timestamp\").alias(\"first_visit\"),\n",
        "        max(\"event_timestamp\").alias(\"last_visit\")\n",
        "    )\n",
        "    \n",
        "    # Calculate derived features\n",
        "    df_features = df_features \\\n",
        "        .withColumn(\"win_rate\", col(\"win_count\") / col(\"total_spins\")) \\\n",
        "        .withColumn(\"net_result_90d\", col(\"coin_out_90d\") - col(\"coin_in_90d\")) \\\n",
        "        .withColumn(\"avg_spins_per_session\", col(\"total_spins\") / col(\"total_sessions\")) \\\n",
        "        .withColumn(\"tenure_days\", datediff(col(\"last_visit\"), col(\"first_visit\"))) \\\n",
        "        .withColumn(\"visit_frequency\", col(\"active_days_90d\") / 90.0)\n",
        "    \n",
        "    # Join with player dimension\n",
        "    df_features = df_features.join(\n",
        "        df_player.select(\"player_id\", \"loyalty_tier\", \"is_vip\"),\n",
        "        \"player_id\",\n",
        "        \"left\"\n",
        "    )\n",
        "    \n",
        "    # Create churn label (1 = churned, 0 = active)\n",
        "    df_features = df_features.withColumn(\n",
        "        \"churned\",\n",
        "        when(col(\"days_since_last_visit\") >= CHURN_DAYS_THRESHOLD, 1).otherwise(0)\n",
        "    )\n",
        "    \n",
        "    return df_features\n",
        "\n",
        "# Create features\n",
        "df_features = create_player_features()\n",
        "print(f\"Created features for {df_features.count()} players\")\n",
        "df_features.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check class balance\n",
        "df_features.groupBy(\"churned\").count().show()\n",
        "\n",
        "# Feature statistics\n",
        "df_features.select(\n",
        "    \"days_since_last_visit\", \"visits_90d\", \"coin_in_90d\",\n",
        "    \"win_rate\", \"avg_bet_amount\", \"tenure_days\"\n",
        ").describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for ML\n",
        "\n",
        "# Handle nulls\n",
        "df_ml = df_features.na.fill({\n",
        "    \"bet_volatility\": 0,\n",
        "    \"loyalty_tier\": \"Unknown\",\n",
        "    \"is_vip\": False\n",
        "})\n",
        "\n",
        "# Feature columns\n",
        "numeric_features = [\n",
        "    \"days_since_last_visit\", \"visits_90d\", \"active_days_90d\",\n",
        "    \"coin_in_90d\", \"coin_out_90d\", \"avg_bet_amount\", \"bet_volatility\",\n",
        "    \"win_rate\", \"total_spins\", \"unique_machines\", \"total_sessions\",\n",
        "    \"avg_spins_per_session\", \"tenure_days\", \"visit_frequency\"\n",
        "]\n",
        "\n",
        "categorical_features = [\"loyalty_tier\"]\n",
        "\n",
        "# Train/test split\n",
        "train_df, test_df = df_ml.randomSplit([0.8, 0.2], seed=42)\n",
        "print(f\"Training set: {train_df.count()} records\")\n",
        "print(f\"Test set: {test_df.count()} records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build ML pipeline\n",
        "\n",
        "# Index categorical features\n",
        "tier_indexer = StringIndexer(\n",
        "    inputCol=\"loyalty_tier\",\n",
        "    outputCol=\"loyalty_tier_idx\",\n",
        "    handleInvalid=\"keep\"\n",
        ")\n",
        "\n",
        "tier_encoder = OneHotEncoder(\n",
        "    inputCol=\"loyalty_tier_idx\",\n",
        "    outputCol=\"loyalty_tier_vec\"\n",
        ")\n",
        "\n",
        "# Assemble features\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=numeric_features + [\"loyalty_tier_vec\"],\n",
        "    outputCol=\"features_raw\"\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler(\n",
        "    inputCol=\"features_raw\",\n",
        "    outputCol=\"features\",\n",
        "    withStd=True,\n",
        "    withMean=True\n",
        ")\n",
        "\n",
        "# Random Forest classifier\n",
        "rf = RandomForestClassifier(\n",
        "    labelCol=\"churned\",\n",
        "    featuresCol=\"features\",\n",
        "    numTrees=100,\n",
        "    maxDepth=10,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = Pipeline(stages=[\n",
        "    tier_indexer,\n",
        "    tier_encoder,\n",
        "    assembler,\n",
        "    scaler,\n",
        "    rf\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train model with MLflow tracking\n",
        "with mlflow.start_run(run_name=\"player_churn_rf\"):\n",
        "    # Log parameters\n",
        "    mlflow.log_param(\"model_type\", \"RandomForest\")\n",
        "    mlflow.log_param(\"num_trees\", 100)\n",
        "    mlflow.log_param(\"max_depth\", 10)\n",
        "    mlflow.log_param(\"churn_threshold_days\", CHURN_DAYS_THRESHOLD)\n",
        "    \n",
        "    # Train\n",
        "    print(\"Training model...\")\n",
        "    model = pipeline.fit(train_df)\n",
        "    \n",
        "    # Predict on test set\n",
        "    predictions = model.transform(test_df)\n",
        "    \n",
        "    # Evaluate\n",
        "    evaluator = BinaryClassificationEvaluator(\n",
        "        labelCol=\"churned\",\n",
        "        rawPredictionCol=\"rawPrediction\",\n",
        "        metricName=\"areaUnderROC\"\n",
        "    )\n",
        "    \n",
        "    auc = evaluator.evaluate(predictions)\n",
        "    print(f\"AUC-ROC: {auc:.4f}\")\n",
        "    \n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"auc_roc\", auc)\n",
        "    \n",
        "    # Log model\n",
        "    mlflow.spark.log_model(model, \"model\")\n",
        "    \n",
        "    print(\"Model logged to MLflow\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "predictions.groupBy(\"churned\", \"prediction\").count() \\\n",
        "    .orderBy(\"churned\", \"prediction\").show()\n",
        "\n",
        "# Calculate precision, recall\n",
        "tp = predictions.filter((col(\"churned\") == 1) & (col(\"prediction\") == 1)).count()\n",
        "fp = predictions.filter((col(\"churned\") == 0) & (col(\"prediction\") == 1)).count()\n",
        "fn = predictions.filter((col(\"churned\") == 1) & (col(\"prediction\") == 0)).count()\n",
        "tn = predictions.filter((col(\"churned\") == 0) & (col(\"prediction\") == 0)).count()\n",
        "\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance\n",
        "rf_model = model.stages[-1]\n",
        "feature_importance = list(zip(\n",
        "    numeric_features + [\"loyalty_tier\"],\n",
        "    rf_model.featureImportances.toArray()\n",
        "))\n",
        "feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nTop 10 Feature Importance:\")\n",
        "for feature, importance in feature_importance[:10]:\n",
        "    print(f\"  {feature}: {importance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Score Players"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Score all players\n",
        "df_scored = model.transform(df_ml)\n",
        "\n",
        "# Extract churn probability\n",
        "from pyspark.ml.functions import vector_to_array\n",
        "\n",
        "df_scores = df_scored.select(\n",
        "    \"player_id\",\n",
        "    \"loyalty_tier\",\n",
        "    \"days_since_last_visit\",\n",
        "    \"coin_in_90d\",\n",
        "    \"prediction\",\n",
        "    vector_to_array(\"probability\")[1].alias(\"churn_probability\")\n",
        ") \\\n",
        ".withColumn(\"risk_tier\",\n",
        "    when(col(\"churn_probability\") >= 0.8, \"Critical\")\n",
        "    .when(col(\"churn_probability\") >= 0.6, \"High\")\n",
        "    .when(col(\"churn_probability\") >= 0.4, \"Medium\")\n",
        "    .otherwise(\"Low\")\n",
        ")\n",
        "\n",
        "# Show high-risk players\n",
        "print(\"High-Risk Players:\")\n",
        "df_scores.filter(col(\"risk_tier\").isin([\"Critical\", \"High\"])) \\\n",
        "    .orderBy(col(\"churn_probability\").desc()) \\\n",
        "    .show(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save scores to Gold layer\n",
        "df_scores.write \\\n",
        "    .format(\"delta\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .saveAsTable(\"gold.player_churn_scores\")\n",
        "\n",
        "print(\"Churn scores saved to gold.player_churn_scores\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Risk tier summary\n",
        "summary = df_scores.groupBy(\"risk_tier\").agg(\n",
        "    count(\"*\").alias(\"player_count\"),\n",
        "    sum(\"coin_in_90d\").alias(\"total_coin_in_90d\"),\n",
        "    avg(\"churn_probability\").alias(\"avg_churn_prob\")\n",
        ").orderBy(col(\"avg_churn_prob\").desc())\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CHURN RISK SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "summary.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
