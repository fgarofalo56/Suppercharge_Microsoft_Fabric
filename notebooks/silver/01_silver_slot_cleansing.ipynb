{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Silver Layer: Slot Telemetry Cleansing & Validation\n",
        "\n",
        "**Notebook:** `01_silver_slot_cleansing`  \n",
        "**Layer:** Silver (Cleansed)  \n",
        "**Purpose:** Clean, validate, and standardize slot telemetry data\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "The Silver layer transforms raw Bronze data into clean, validated, and standardized records. This notebook implements:\n",
        "\n",
        "- Data type enforcement\n",
        "- Null handling and default values\n",
        "- Deduplication\n",
        "- Business rule validation\n",
        "- Data quality scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "BRONZE_TABLE = \"bronze_slot_telemetry\"\n",
        "SILVER_TABLE = \"silver_slot_telemetry\"\n",
        "SILVER_LAKEHOUSE = \"lh_silver\"\n",
        "\n",
        "# Processing parameters\n",
        "DEDUP_WINDOW_HOURS = 24\n",
        "MIN_QUALITY_SCORE = 0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import *\n",
        "from delta.tables import DeltaTable\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read from Bronze\n",
        "df_bronze = spark.table(BRONZE_TABLE)\n",
        "print(f\"Bronze records: {df_bronze.count()}\")\n",
        "df_bronze.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Type Enforcement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enforce_data_types(df):\n",
        "    \"\"\"\n",
        "    Enforce correct data types and handle conversions.\n",
        "    \"\"\"\n",
        "    return df \\\n",
        "        .withColumn(\"event_timestamp_clean\", to_timestamp(col(\"event_timestamp\"))) \\\n",
        "        .withColumn(\"bet_amount_clean\", col(\"bet_amount\").cast(DoubleType())) \\\n",
        "        .withColumn(\"win_amount_clean\", col(\"win_amount\").cast(DoubleType())) \\\n",
        "        .withColumn(\"denomination_clean\", col(\"denomination\").cast(DoubleType())) \\\n",
        "        .withColumn(\"credits_wagered_clean\", col(\"credits_wagered\").cast(IntegerType())) \\\n",
        "        .withColumn(\"credits_won_clean\", col(\"credits_won\").cast(IntegerType()))\n",
        "\n",
        "df_typed = enforce_data_types(df_bronze)\n",
        "print(\"Data types enforced\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Null Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def handle_nulls(df):\n",
        "    \"\"\"\n",
        "    Handle null values with business-appropriate defaults.\n",
        "    \"\"\"\n",
        "    return df \\\n",
        "        .withColumn(\"bet_amount_clean\", coalesce(col(\"bet_amount_clean\"), lit(0.0))) \\\n",
        "        .withColumn(\"win_amount_clean\", coalesce(col(\"win_amount_clean\"), lit(0.0))) \\\n",
        "        .withColumn(\"credits_wagered_clean\", coalesce(col(\"credits_wagered_clean\"), lit(0))) \\\n",
        "        .withColumn(\"credits_won_clean\", coalesce(col(\"credits_won_clean\"), lit(0))) \\\n",
        "        .withColumn(\"player_id_clean\", coalesce(col(\"player_id\"), lit(\"ANONYMOUS\"))) \\\n",
        "        .withColumn(\"casino_id_clean\", coalesce(col(\"casino_id\"), lit(\"UNKNOWN\"))) \\\n",
        "        .withColumn(\"floor_location_clean\", coalesce(col(\"floor_location\"), lit(\"UNKNOWN\")))\n",
        "\n",
        "df_nulls_handled = handle_nulls(df_typed)\n",
        "print(\"Nulls handled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deduplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def deduplicate_records(df):\n",
        "    \"\"\"\n",
        "    Remove duplicate records based on event_id, keeping the latest.\n",
        "    \"\"\"\n",
        "    window = Window.partitionBy(\"event_id\").orderBy(col(\"_ingestion_timestamp\").desc())\n",
        "    \n",
        "    df_deduped = df \\\n",
        "        .withColumn(\"_row_num\", row_number().over(window)) \\\n",
        "        .filter(col(\"_row_num\") == 1) \\\n",
        "        .drop(\"_row_num\")\n",
        "    \n",
        "    return df_deduped\n",
        "\n",
        "df_deduped = deduplicate_records(df_nulls_handled)\n",
        "print(f\"After deduplication: {df_deduped.count()} records\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Business Rule Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_business_rules(df):\n",
        "    \"\"\"\n",
        "    Apply business validation rules and flag issues.\n",
        "    \"\"\"\n",
        "    return df \\\n",
        "        .withColumn(\"is_valid_bet\", \n",
        "            (col(\"bet_amount_clean\") >= 0) & \n",
        "            (col(\"bet_amount_clean\") <= 10000)) \\\n",
        "        .withColumn(\"is_valid_win\", \n",
        "            col(\"win_amount_clean\") >= 0) \\\n",
        "        .withColumn(\"is_valid_timestamp\", \n",
        "            col(\"event_timestamp_clean\").isNotNull() & \n",
        "            (col(\"event_timestamp_clean\") <= current_timestamp())) \\\n",
        "        .withColumn(\"is_large_win\", \n",
        "            col(\"win_amount_clean\") >= 1200)  # W-2G threshold\n",
        "\n",
        "df_validated = apply_business_rules(df_deduped)\n",
        "print(\"Business rules applied\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Quality Scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_quality_score(df):\n",
        "    \"\"\"\n",
        "    Calculate a data quality score for each record.\n",
        "    \"\"\"\n",
        "    return df.withColumn(\"quality_score\",\n",
        "        (col(\"is_valid_bet\").cast(\"int\") +\n",
        "         col(\"is_valid_win\").cast(\"int\") +\n",
        "         col(\"is_valid_timestamp\").cast(\"int\") +\n",
        "         when(col(\"machine_id\").isNotNull(), 1).otherwise(0) +\n",
        "         when(col(\"event_type\").isNotNull(), 1).otherwise(0)\n",
        "        ) / 5.0\n",
        "    )\n",
        "\n",
        "df_scored = calculate_quality_score(df_validated)\n",
        "print(\"Quality scores calculated\")\n",
        "df_scored.select(\"quality_score\").describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Silver Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select and rename columns for Silver schema\n",
        "df_silver = df_scored.select(\n",
        "    col(\"event_id\"),\n",
        "    col(\"machine_id\"),\n",
        "    col(\"casino_id_clean\").alias(\"casino_id\"),\n",
        "    col(\"floor_location_clean\").alias(\"floor_location\"),\n",
        "    col(\"event_timestamp_clean\").alias(\"event_timestamp\"),\n",
        "    col(\"event_type\"),\n",
        "    col(\"denomination_clean\").alias(\"denomination\"),\n",
        "    col(\"bet_amount_clean\").alias(\"bet_amount\"),\n",
        "    col(\"win_amount_clean\").alias(\"win_amount\"),\n",
        "    col(\"jackpot_contribution\"),\n",
        "    col(\"credits_wagered_clean\").alias(\"credits_wagered\"),\n",
        "    col(\"credits_won_clean\").alias(\"credits_won\"),\n",
        "    col(\"player_id_clean\").alias(\"player_id\"),\n",
        "    col(\"session_id\"),\n",
        "    col(\"is_bonus_round\"),\n",
        "    col(\"game_outcome\"),\n",
        "    col(\"is_valid_bet\"),\n",
        "    col(\"is_valid_win\"),\n",
        "    col(\"is_large_win\"),\n",
        "    col(\"quality_score\"),\n",
        "    col(\"_ingestion_timestamp\").alias(\"bronze_ingestion_timestamp\"),\n",
        "    current_timestamp().alias(\"silver_processed_timestamp\"),\n",
        "    year(col(\"event_timestamp_clean\")).alias(\"year\"),\n",
        "    month(col(\"event_timestamp_clean\")).alias(\"month\"),\n",
        "    dayofmonth(col(\"event_timestamp_clean\")).alias(\"day\")\n",
        ")\n",
        "\n",
        "# Filter by quality score\n",
        "df_silver_filtered = df_silver.filter(col(\"quality_score\") >= MIN_QUALITY_SCORE)\n",
        "\n",
        "print(f\"Silver records (quality >= {MIN_QUALITY_SCORE}): {df_silver_filtered.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write to Silver lakehouse\n",
        "df_silver_filtered.write \\\n",
        "    .format(\"delta\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .partitionBy(\"year\", \"month\", \"day\") \\\n",
        "    .option(\"overwriteSchema\", \"true\") \\\n",
        "    .saveAsTable(SILVER_TABLE)\n",
        "\n",
        "print(f\"Wrote to {SILVER_TABLE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quality report\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"SILVER LAYER QUALITY REPORT\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Input records (Bronze): {df_bronze.count()}\")\n",
        "print(f\"After deduplication: {df_deduped.count()}\")\n",
        "print(f\"Output records (Silver): {df_silver_filtered.count()}\")\n",
        "print(f\"Records filtered by quality: {df_deduped.count() - df_silver_filtered.count()}\")\n",
        "print(f\"\\nLarge wins (>=$1,200): {df_silver_filtered.filter(col('is_large_win')).count()}\")\n",
        "print(\"=\"*50)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
