# Tutorial 00: Environment Setup

> **ğŸ  [Home](../../README.md)** > **ğŸ“– [Tutorials](../README.md)** > **âš™ï¸ Environment Setup**

---

<div align="center">

![Difficulty](https://img.shields.io/badge/â­_Difficulty-Beginner-brightgreen?style=for-the-badge)
![Duration](https://img.shields.io/badge/â±ï¸_Duration-45--60_mins-blue?style=for-the-badge)
![Prerequisites](https://img.shields.io/badge/ğŸ“‹_Prerequisites-Azure_Subscription-orange?style=for-the-badge)

</div>

---

## ğŸ“ Tutorial 00: Environment Setup

| | |
|---|---|
| **Difficulty** | â­ Beginner |
| **Time** | â±ï¸ 30-45 minutes |
| **Prerequisites** | Azure subscription with Fabric enabled |

---

### ğŸ“ Progress Tracker

<div align="center">

<table>
<thead>
<tr>
<th align="center" width="10%">Tutorial</th>
<th align="left" width="45%">Name</th>
<th align="center" width="15%">Status</th>
<th align="center" width="15%">Duration</th>
<th align="center" width="15%">Difficulty</th>
</tr>
</thead>
<tbody>
<tr style="background-color: #e8f5e9;">
<td align="center"><strong>00</strong></td>
<td><strong>ğŸ‘‰ <a href="../00-environment-setup/README.md">Environment Setup</a></strong></td>
<td align="center"><img src="https://img.shields.io/badge/â—-CURRENT-blue?style=flat-square" alt="Current"></td>
<td align="center">45-60 min</td>
<td align="center">â­ Beginner</td>
</tr>
<tr>
<td align="center">01</td>
<td><a href="../01-bronze-layer/README.md">ğŸ¥‰ Bronze Layer</a></td>
<td align="center"><img src="https://img.shields.io/badge/â—‹-TODO-lightgrey?style=flat-square" alt="Todo"></td>
<td align="center">60-90 min</td>
<td align="center">â­ Beginner</td>
</tr>
<tr>
<td align="center">02</td>
<td><a href="../02-silver-layer/README.md">ğŸ¥ˆ Silver Layer</a></td>
<td align="center"><img src="https://img.shields.io/badge/â—‹-TODO-lightgrey?style=flat-square" alt="Todo"></td>
<td align="center">60-90 min</td>
<td align="center">â­â­ Intermediate</td>
</tr>
<tr>
<td align="center">03</td>
<td><a href="../03-gold-layer/README.md">ğŸ¥‡ Gold Layer</a></td>
<td align="center"><img src="https://img.shields.io/badge/â—‹-TODO-lightgrey?style=flat-square" alt="Todo"></td>
<td align="center">90-120 min</td>
<td align="center">â­â­ Intermediate</td>
</tr>
<tr>
<td align="center">04</td>
<td><a href="../04-real-time-analytics/README.md">âš¡ Real-Time Analytics</a></td>
<td align="center"><img src="https://img.shields.io/badge/â—‹-TODO-lightgrey?style=flat-square" alt="Todo"></td>
<td align="center">90-120 min</td>
<td align="center">â­â­â­ Advanced</td>
</tr>
<tr>
<td align="center">05</td>
<td><a href="../05-direct-lake-powerbi/README.md">ğŸ“Š Direct Lake & Power BI</a></td>
<td align="center"><img src="https://img.shields.io/badge/â—‹-TODO-lightgrey?style=flat-square" alt="Todo"></td>
<td align="center">60-90 min</td>
<td align="center">â­â­ Intermediate</td>
</tr>
<tr>
<td align="center">06</td>
<td><a href="../06-data-pipelines/README.md">ğŸ”„ Data Pipelines</a></td>
<td align="center"><img src="https://img.shields.io/badge/â—‹-TODO-lightgrey?style=flat-square" alt="Todo"></td>
<td align="center">60-90 min</td>
<td align="center">â­â­ Intermediate</td>
</tr>
<tr>
<td align="center">07</td>
<td><a href="../07-governance-purview/README.md">ğŸ›¡ï¸ Governance & Purview</a></td>
<td align="center"><img src="https://img.shields.io/badge/â—‹-TODO-lightgrey?style=flat-square" alt="Todo"></td>
<td align="center">60-90 min</td>
<td align="center">â­â­ Intermediate</td>
</tr>
<tr>
<td align="center">08</td>
<td><a href="../08-database-mirroring/README.md">ğŸ”„ Database Mirroring</a></td>
<td align="center"><img src="https://img.shields.io/badge/â—‹-TODO-lightgrey?style=flat-square" alt="Todo"></td>
<td align="center">60-90 min</td>
<td align="center">â­â­ Intermediate</td>
</tr>
<tr>
<td align="center">09</td>
<td><a href="../09-advanced-ai-ml/README.md">ğŸ¤– Advanced AI/ML</a></td>
<td align="center"><img src="https://img.shields.io/badge/â—‹-TODO-lightgrey?style=flat-square" alt="Todo"></td>
<td align="center">90-120 min</td>
<td align="center">â­â­â­ Advanced</td>
</tr>
</tbody>
</table>

<p><em>ğŸ’¡ Tip: Click any tutorial name to jump directly to it</em></p>

</div>

---

| Navigation | |
|---|---|
| **Previous** | N/A - This is the first tutorial |
| **Next** | [01-Bronze Layer](../01-bronze-layer/README.md) â¡ï¸ |

---

## ğŸ“– Overview

This tutorial guides you through setting up your Microsoft Fabric environment for the Casino/Gaming POC. You will create the foundational workspace and Lakehouse infrastructure needed for the medallion architecture.

```mermaid
graph LR
    subgraph "What We're Building"
        A[Azure Subscription] --> B[Fabric Workspace]
        B --> C[ğŸ¥‰ lh_bronze]
        B --> D[ğŸ¥ˆ lh_silver]
        B --> E[ğŸ¥‡ lh_gold]
    end
```

---

## ğŸ¯ Learning Objectives

By the end of this tutorial, you will be able to:

- [ ] Understand Microsoft Fabric workspace structure
- [ ] Create and configure a Fabric workspace
- [ ] Create Lakehouses for the medallion architecture
- [ ] Connect to Azure Data Lake Storage
- [ ] Configure workspace settings and access

---

## ğŸ“‹ Prerequisites

Before starting, ensure you have:

- [ ] Azure subscription with Fabric enabled
- [ ] Fabric capacity (F64 recommended, F2 minimum for POC)
- [ ] Azure CLI installed locally (optional)
- [ ] Access to Fabric portal (app.fabric.microsoft.com)

> ğŸ“‹ **Prerequisites:** If you don't have a Fabric capacity, you can start a free trial at [app.fabric.microsoft.com](https://app.fabric.microsoft.com). Trial capacity provides 60 days of limited compute units.

---

## ğŸ› ï¸ Step 1: Access Microsoft Fabric

1. Navigate to [Microsoft Fabric](https://app.fabric.microsoft.com)
2. Sign in with your Azure AD / Entra ID account
3. Verify you see the Fabric home page

### Verify Capacity Access

1. Click on **Settings** (gear icon) in the top right
2. Select **Admin portal** (if you have admin access)
3. Navigate to **Capacity settings**
4. Confirm your Fabric capacity is available and running

> ğŸ“¸ **Screenshot**: Azure Portal - Fabric Capacity Creation
> 
> _To be added: Navigate to Azure Portal > Create a resource > Microsoft Fabric > Capacity and capture the capacity creation blade showing SKU selection (F64), region, and capacity name fields_

> âš ï¸ **Warning:** If your capacity is paused, notebooks and data processing will not work. Ensure the capacity is in "Active" state before proceeding. Resume can take 2-3 minutes.

---

## ğŸ› ï¸ Step 2: Create Workspace

### Create a New Workspace

1. In the left navigation, click **Workspaces**
2. Click **+ New workspace**
3. Configure the workspace:

   | Setting | Value |
   |---------|-------|
   | Name | `casino-fabric-poc` |
   | Description | Casino/Gaming Fabric POC - Medallion Architecture |
   | License mode | Fabric capacity |
   | Capacity | Select your Fabric capacity |

4. Click **Apply**

> ğŸ“¸ **Screenshot**: Fabric Portal - Workspace Creation
> 
> _To be added: Navigate to Fabric portal > Workspaces > + New workspace and capture the workspace creation dialog showing Name, Description, License mode, and Capacity dropdown fields_

### Configure Workspace Settings

1. Open workspace settings (three dots > Settings)
2. Configure the following:

   **General:**
   - Contact list: Add team members
   - Default storage format: Delta

   **Premium/Fabric:**
   - License mode: Fabric capacity
   - Default storage format: Delta/Parquet

> ğŸ’¡ **Pro Tip:** Using Delta format enables time travel, ACID transactions, and schema evolution - all critical features for our medallion architecture. Always choose Delta over Parquet for production workloads.

---

## ğŸ› ï¸ Step 3: Create Lakehouses

We'll create three Lakehouses for the medallion architecture.

![Microsoft Fabric Lakehouse Overview](https://learn.microsoft.com/en-us/fabric/data-engineering/media/lakehouse-overview/lakehouse-overview.gif)

*Source: [What is a Lakehouse in Microsoft Fabric?](https://learn.microsoft.com/en-us/fabric/data-engineering/lakehouse-overview)*

```mermaid
graph TB
    subgraph "Medallion Architecture"
        direction LR
        B[ğŸ¥‰ lh_bronze<br/>Raw Data] --> S[ğŸ¥ˆ lh_silver<br/>Cleansed Data]
        S --> G[ğŸ¥‡ lh_gold<br/>Business Ready]
    end
```

### ğŸ¥‰ Bronze Lakehouse (Raw Data)

1. In your workspace, click **+ New** > **Lakehouse**
2. Name: `lh_bronze`
3. Click **Create**

### ğŸ¥ˆ Silver Lakehouse (Cleansed Data)

1. Click **+ New** > **Lakehouse**
2. Name: `lh_silver`
3. Click **Create**

### ğŸ¥‡ Gold Lakehouse (Business Ready)

1. Click **+ New** > **Lakehouse**
2. Name: `lh_gold`
3. Click **Create**

### Verify Lakehouses

Your workspace should now contain:

```
casino-fabric-poc/
â”œâ”€â”€ ğŸ¥‰ lh_bronze
â”œâ”€â”€ ğŸ¥ˆ lh_silver
â””â”€â”€ ğŸ¥‡ lh_gold
```

---

## ğŸ› ï¸ Step 4: Connect to External Storage (Optional)

If you deployed the ADLS Gen2 storage account via Bicep, connect it as a shortcut.

### Create OneLake Shortcut to ADLS

1. Open `lh_bronze`
2. In the **Explorer** pane, right-click on **Files**
3. Select **New shortcut**
4. Choose **Azure Data Lake Storage Gen2**
5. Enter connection details:

   | Setting | Value |
   |---------|-------|
   | URL | Your ADLS DFS endpoint |
   | Connection | Create new |
   | Authentication | Organizational account |

6. Browse to the `landing` container
7. Name the shortcut: `landing_zone`
8. Click **Create**

> ğŸ’¡ **Pro Tip:** Shortcuts allow you to access external data without copying it, reducing storage costs and keeping data in sync. Use shortcuts for large archives or shared data sources.

---

## ğŸ› ï¸ Step 5: Configure Workspace Access

### Add Team Members

1. Open workspace settings
2. Navigate to **Access**
3. Add users with appropriate roles:

   | Role | Who | Permissions |
   |------|-----|-------------|
   | Admin | Workspace owners | Full control |
   | Member | Data engineers | Edit all items |
   | Contributor | Developers | Create/edit |
   | Viewer | Business users | Read only |

> âš ï¸ **Warning:** Be careful when assigning Admin roles. Admins can delete the workspace and all its contents.

---

## ğŸ› ï¸ Step 6: Install Local Tools (Optional)

For local development and data generation, install these tools:

### Required Tools

| Tool | Purpose | Installation |
|------|---------|--------------|
| Python 3.10+ | Data generation scripts | [python.org](https://python.org) |
| VS Code | Code editor | [code.visualstudio.com](https://code.visualstudio.com) |
| Azure CLI | Azure management | [docs.microsoft.com](https://docs.microsoft.com/cli/azure/install-azure-cli) |

### Python Environment Setup

> ğŸ’¡ **Pro Tip:** Use a virtual environment to isolate project dependencies and avoid conflicts with system Python packages.

> ğŸ“¸ **Screenshot**: VS Code - Extension Installation
> 
> _To be added: Open VS Code > Extensions panel and capture the installed extensions including Python, Jupyter, Azure Account, and Microsoft Fabric extensions with their enabled status_

```bash
# Create virtual environment
python -m venv .venv

# Activate (Windows)
.venv\Scripts\activate

# Activate (macOS/Linux)
source .venv/bin/activate

# Install dependencies (if requirements.txt exists)
pip install -r requirements.txt
```

---

## âœ… Step 7: Verify Setup

### Run Verification Checks

1. **Workspace accessible:** Can see all three Lakehouses
2. **Capacity assigned:** Workspace shows "Premium" or "Fabric" badge
3. **Shortcuts working:** Can browse landing zone (if configured)
4. **Permissions correct:** Team members can access

### Create a Test Table

1. Open `lh_bronze`
2. Click **Open notebook** > **New notebook**
3. Run this test code:

```python
# Test Lakehouse connectivity
from pyspark.sql import SparkSession

# Create test data
data = [("test", 1), ("data", 2)]
df = spark.createDataFrame(data, ["name", "value"])

# Write to Bronze Lakehouse
df.write.format("delta").mode("overwrite").save("Tables/test_connection")

print("âœ… Success! Lakehouse is configured correctly.")
```

> ğŸ’¡ **Pro Tip:** First-time notebook execution can take 2-3 minutes while Fabric provisions a Spark cluster. Subsequent runs will be faster.

4. Verify the `test_connection` table appears in the Tables folder
5. Delete the test table when done:

```python
# Clean up test table
spark.sql("DROP TABLE IF EXISTS test_connection")
print("âœ… Test table cleaned up.")
```

---

## âœ… Validation Checklist

Before moving to the next tutorial, verify:

- [ ] **Workspace Created** - `casino-fabric-poc` workspace exists and is accessible
- [ ] **Capacity Assigned** - Fabric capacity is active and assigned to workspace
- [ ] **Bronze Lakehouse** - `lh_bronze` created successfully
- [ ] **Silver Lakehouse** - `lh_silver` created successfully
- [ ] **Gold Lakehouse** - `lh_gold` created successfully
- [ ] **Shortcut Configuration** - ADLS shortcut accessible (if configured)
- [ ] **Test Notebook Runs** - Successfully executed test notebook without errors
- [ ] **Table Operations Work** - Created and deleted test table successfully

<details>
<summary>ğŸ” How to verify each item</summary>

### Workspace Created
```powershell
# Navigate to app.fabric.microsoft.com
# Verify workspace appears in left navigation
```

### Capacity Assigned
1. Click Settings (gear icon) > Admin portal
2. Go to Capacity settings
3. Verify capacity status = "Active"

### Lakehouses Created
```python
# In any notebook, run:
spark.sql("SHOW DATABASES").show()
# Should list: lh_bronze, lh_silver, lh_gold
```

### Test Notebook Runs
```python
# Run this verification cell:
from pyspark.sql import SparkSession

# Create test data
data = [("environment", "ready"), ("setup", "complete")]
df = spark.createDataFrame(data, ["key", "value"])

# Write to Bronze
df.write.format("delta").mode("overwrite").save("Tables/env_test")

# Read back
df_check = spark.read.format("delta").load("Tables/env_test")
print(f"âœ… Environment test passed: {df_check.count()} records")

# Cleanup
spark.sql("DROP TABLE IF EXISTS env_test")
```

### Capacity Check
```bash
# Check capacity CU usage in Fabric portal:
# Settings > Admin portal > Capacity settings > Usage
# Verify CUs available and not at 100%
```

</details>

---

## ğŸ”§ Troubleshooting

### Workspace Creation Fails

| Issue | Solution |
|-------|----------|
| "Fabric not enabled" | Contact your tenant admin to enable Fabric |
| "No capacity available" | Start a trial or provision a capacity |
| "Permission denied" | Ensure your account has workspace creation rights |

### Shortcut Connection Fails

| Issue | Solution |
|-------|----------|
| "Cannot connect" | Verify ADLS account exists and is accessible |
| "Firewall blocked" | Check firewall/private endpoint settings |
| "Access denied" | Ensure you have Storage Blob Data Reader role |

### Notebook Won't Run

| Issue | Solution |
|-------|----------|
| "Capacity not available" | Verify capacity is running (not paused) |
| "Spark pool error" | Wait 2-3 minutes for first-time Spark startup |
| "Out of memory" | Reduce data size or upgrade capacity |

> ğŸ’¡ **Pro Tip:** If Spark startup fails repeatedly, try detaching and reattaching the Lakehouse to the notebook. This forces a fresh cluster provisioning.

---

## ğŸ‰ Summary

Congratulations! You have successfully:

- âœ… Created a Microsoft Fabric workspace for the Casino POC
- âœ… Set up the medallion architecture with Bronze, Silver, and Gold Lakehouses
- âœ… Configured external storage connectivity (optional)
- âœ… Verified the environment is ready for data ingestion

Your environment is now ready to start building the data platform!

---

## â¡ï¸ Next Steps

Continue to **[Tutorial 01: Bronze Layer](../01-bronze-layer/README.md)** to start ingesting raw data into the Bronze layer.

---

## ğŸ“š Resources

- [Microsoft Fabric Documentation](https://learn.microsoft.com/fabric/)
- [Lakehouse Overview](https://learn.microsoft.com/fabric/data-engineering/lakehouse-overview)
- [Workspace Management](https://learn.microsoft.com/fabric/get-started/workspaces)
- [OneLake Shortcuts](https://learn.microsoft.com/fabric/onelake/onelake-shortcuts)

---

## ğŸ§­ Navigation

| Previous | Up | Next |
|----------|-----|------|
| N/A | [ğŸ“– Tutorials Index](../README.md) | [01-Bronze Layer](../01-bronze-layer/README.md) â¡ï¸ |

---

> ğŸ’¬ **Questions or issues?** Open an issue in the [GitHub repository](https://github.com/your-repo/issues).
